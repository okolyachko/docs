Alan AI iOS SDK
===============

.. raw:: html

   <a href="https://github.com/alan-ai/alan-sdk-ios/releases">
   <img src="https://img.shields.io/github/v/release/alan-ai/alan-sdk-ios" align="left" /></a>
   <br/>

Alan AI can be integrated with iOS apps developed in Swift and Objective-C. 

Integrating with Alan AI
------------------------

To add a conversational experience to an iOS app, you need to do the following:

1. `Get the Alan iOS SDK framework <#step-1-get-the-alan-ios-sdk-framework>`__
2. `Integrate with the app <#step-2-integrate-with-the-app>`__: Swift or Objective-C. As part of this process, you will:

   a. `Add the Alan AI Config object to your app <#alanconfig-object>`__

   b. `Add the Alan AI button to your app <#alan-button>`__


Step 1. Get the Alan AI iOS SDK framework
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

First, you need to get the Alan AI iOS SDK framework and set up your XCode project to be used with Alan AI. You can do it in two ways:

-  Set up an XCode project with CocoaPods
-  Set up an XCode project manually

.. tabbed:: Setup with CocoaPods

   .. _Setup with CocoaPods:
   
   Do the following:

   1. On the machine, open Terminal and install CocoaPods:

      .. code-block::
         :caption: Terminal

         sudo gem install cocoapods

   2. Go to the project folder and create a Podfile for the project:

      .. code-block::
         :caption: Terminal

         pod init

   3. Open the Podfile and edit it:

      .. code-block:: ruby
         :caption: Podfile

         use_frameworks!
         platform :ios, '11.0'
         target '<Your Target Name>' do
         pod 'AlanSDK-iOS'
         end

   4. In the project folder, install the dependencies for the project:

      .. code-block:: 
         :caption: Terminal

         pod install
         pod update

   5. In iOS, the user must explicitly grant permission for an app to `access the user's data and resources <https://developer.apple.com/documentation/bundleresources/information_property_list/protected_resources>`__. An app with the Alan AI button requires access to:

      - User's device microphone for voice interactions
      - User's device camera for testing Alan AI projects on mobile

      To comply with this requirement, you must add ``NSMicrophoneUsageDescription`` and ``NSCameraUsageDescription`` keys to the ``Info.plist`` file of your app and provide a message why your app requires access to the microphone and camera. The message will be displayed only when Alan AI needs to activate the microphone or camera.

      To add the key:
   
      a. In the Xcode project, go to the **Info** tab. 
      b. In the **Custom iOS Target Properties** section, hover over any key in the list and click the plus icon to the right.
      c. From the list, select **Privacy - Microphone Usage Description**.
      d. In the **Value** field to the right, provide a description for the added key. This description will be displayed to the user when the app is launched.  
      e. Repeat the steps above to add the **Privacy - Camera Usage Description** key.

      .. image:: /_static/assets/img/ios-quickstart-objc/pods-mic.png

   6. To allow the background mode for the iOS app, go to the **Signing and Capabilities** tab. In the top left corner, click **+ Capability** and in the capabilities list, double-click **Background Modes**. In the **Modes** list, select the **Audio, AirPlay, and Picture in Picture** check box. 

      .. image:: /_static/assets/img/ios-quickstart-objc/pods-background.png

   7. The background mode must also be turned on in the Alan AI Studio project. In Alan AI Studio, at the top of the code editor, click **Integrations**, go to the iOS tab and enable the **Keep active while the app is in the background** option.


.. tabbed:: Manual setup

   .. _Manual setup:

   Do the following:

   1. Open the Alan AI iOS SDK release page on Alan AI GitHub.
   2. Download the ``AlanSDK.xcframework_<x.x.x>.zip`` file from the latest release and extract ``AlanSDK.xcframework`` from the ZIP archive.
   
   .. image:: /_static/assets/img/ios-quickstart-objc/download.png
   
   3. Drag ``AlanSDK.xcframework`` and drop it onto the root node of the Xcode project.    
   4. Select the **Copy items if needed** check box if it is not selected.

      .. image:: /_static/assets/img/ios-quickstart-objc/copy-2.png
   
   5. In the project tree, select the XCode project file and go to the **General** tab. Under the **Frameworks, Libraries, and Embedded Content** section, find ``AlanSDK.xcframework`` and select **Embed & Sign** from the list.
   
      .. image:: /_static/assets/img/ios-quickstart-objc/embedded.png
   
   
   6. In iOS, the user must explicitly grant permission for an app to `access the user's data and resources <https://developer.apple.com/design/human-interface-guidelines/ios/app-architecture/accessing-user-data/>`__. An app with the Alan AI button requires access to:

      - User's device microphone for voice interactions
      - User's device camera for testing Alan AI projects on mobile
   
      To comply with this requirement, you must add ``NSMicrophoneUsageDescription`` and ``NSCameraUsageDescription`` keys to the ``Info.plist`` file of your app and provide a message why your app requires access to the microphone and camera. The message will be displayed only when Alan AI needs to activate the microphone or camera.  
      To add the key:

      a. In the Xcode project, go to the **Info** tab.
      b. In the **Custom iOS Target Properties** section, hover over any key in the list and click the plus icon to the right.
      c. From the list, select **Privacy - Microphone Usage Description**.
      d. In the **Value** field to the right, provide a description for the added key. This description will be displayed to the user when the app is launched.
      e. Repeat the steps above to add the **Privacy - Camera Usage Description** key.

      .. image:: /_static/assets/img/ios-quickstart-objc/mic.png

   7. To allow the background mode for the iOS app, go to the **Signing and Capabilities** tab. In the top left corner, click **+Capability** and in the capabilities list, double-click **Background Modes**. In the **Modes** list, select the **Audio, AirPlay, and Picture in Picture** check box. 

      .. image:: /_static/assets/img/ios-quickstart-objc/background.png
   
   8. The background mode must also be turned on in the Alan AI Studio project. In Alan AI Studio, at the top of the code editor, click **Integrations**, go to the iOS tab and enable the **Keep active while the app is in the background** option.

Step 2. Integrate with the app
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. note::
   The instructions below apply to the Storyboard user interface.

You need to integrate Alan AI with your app written in: 

- Swift 
- Objective-C

.. tabbed:: Swift

   In the Xcode project, open the ``ViewController.swift`` file. You need to add the following Swift snippet to your view controller:

   1. At the top of the file, import AlanSDK:

      .. code-block:: swift
         :caption: Client app

         import AlanSDK

   2. In the ``ViewController`` class, define the ``AlanButton`` variable:

      .. code-block:: swift
         :caption: Client app

         fileprivate var button: AlanButton!

   3. In ``viewDidLoad()``, set up ``AlanButton``. For more details, see `Alan AI Config object <#alanconfig-object>`__ and `Alan AI button <#alan-button>`__. 
   
      .. code-block:: swift
         :caption: Client app
   
         import UIKit
         import AlanSDK

         class ViewController: UIViewController {

           /// Alan AI button
           fileprivate var button: AlanButton!
           override func viewDidLoad() {
             super.viewDidLoad()
			
             /// Setup the Alan AI button
             self.setupAlan()
           }

           fileprivate func setupAlan() {

             /// Define the project key
             let config = AlanConfig(key: "")
			
             ///  Init the Alan AI button
             self.button = AlanButton(config: config)
			
             /// Add the button to the view
             self.view.addSubview(self.button)
             self.button.translatesAutoresizingMaskIntoConstraints = false
			
             /// Align the button on the view
             let views = ["button" : self.button!]
             let verticalButton = NSLayoutConstraint.constraints(withVisualFormat: "V:|-(>=0@299)-[button(64)]-40-|", options: NSLayoutConstraint.FormatOptions(), metrics: nil, views: views)
             let horizontalButton = NSLayoutConstraint.constraints(withVisualFormat: "H:|-(>=0@299)-[button(64)]-20-|", options: NSLayoutConstraint.FormatOptions(), metrics: nil, views: views)
             self.view.addConstraints(verticalButton + horizontalButton)
           }
         }

   4. In ``let config = AlanConfig(key: "")``, define the Alan AI SDK key for your Alan AI Studio project. To get the key, in Alan AI Studio, at the top of the code editor, click **Integrations** and copy the value from the **Alan SDK Key** field.

   5. Run the app and tap the Alan AI button to speak.

.. tabbed:: Objective-C

   Add this Objective-C snippet to your view controller.

   1. Import AlanSDK:

      .. code-block:: objective-c
         :caption: Client app

         @import AlanSDK;

   2. Define the ``AlanButton`` variable:

      .. code-block:: objective-c
         :caption: Client app

         @property (nonatomic) AlanButton* button;

   3. In ``viewDidLoad``, set up ``AlanButton``. For more details, see `Alan AI Config object <#alanconfig-object>`__ and `Alan AI button <#alan-button>`__.

      .. code-block:: objective-c
         :caption: Client app

         AlanConfig* config = [[AlanConfig alloc] initWithKey:@"YOUR_KEY_FROM_ALAN_STUDIO_HERE"];
         self.button = [[AlanButton alloc] initWithConfig:config];
         [self.button setTranslatesAutoresizingMaskIntoConstraints:NO];
         [self.view addSubview:self.button];
         NSLayoutConstraint* b = [NSLayoutConstraint constraintWithItem:self.button attribute:NSLayoutAttributeBottom relatedBy:NSLayoutRelationEqual toItem:self.view attribute:NSLayoutAttributeBottom multiplier:1 constant:-40.0];
         NSLayoutConstraint* r = [NSLayoutConstraint constraintWithItem:self.button attribute:NSLayoutAttributeRight relatedBy:NSLayoutRelationEqual toItem:self.view attribute:NSLayoutAttributeRight multiplier:1 constant:-20];
         NSLayoutConstraint* w = [NSLayoutConstraint constraintWithItem:self.button attribute:NSLayoutAttributeWidth relatedBy:NSLayoutRelationEqual toItem:nil attribute:NSLayoutAttributeNotAnAttribute multiplier:1 constant:64.0];
         NSLayoutConstraint* h = [NSLayoutConstraint constraintWithItem:self.button attribute:NSLayoutAttributeHeight relatedBy:NSLayoutRelationEqual toItem:nil attribute:NSLayoutAttributeNotAnAttribute multiplier:1 constant:64.0];
         [self.view addConstraints:@[b, r, w, h]];

   4. Run the app and tap the Alan AI button to speak.


AlanConfig object
^^^^^^^^^^^^^^^^^

The ``AlanConfig`` object describes the parameters that are provided for ``AlanButton``.

1. Create a new ``AlanConfig`` instance with your Alan AI SDK key:

   .. code-block:: objective-c
      :caption: Client app

      - (instancetype)initWithKey:(NSString *)key;

   +------------+------------+------------------------------------------------------------+
   | **Name**   | **Type**   | **Description**                                            |
   +============+============+============================================================+
   | ``key``    | NSString   |  The Alan AI SDK key for your project in Alan AI Studio.   |
   +------------+------------+------------------------------------------------------------+

2. Create a new ``AlanConfig`` instance with your Alan AI SDK key
   and custom data object:

   .. code-block:: objective-c
      :caption: Client app

      - (instancetype)initWithKey:(NSString *)key dataObject:(NSDictionary *)dataObject;

   +------------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
   | **Name**         | **Type**       | **Description**                                                                                                                                                                                     |
   +==================+================+=====================================================================================================================================================================================================+
   | ``key``          | NSString       |  The Alan AI SDK key for a project in Alan AI Studio.                                                                                                                                               |
   +------------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
   | ``dataObject``   | NSDictionary   | (Optional) A valid JSON string or JSON object with authentication or configuration data to be sent to the dialog script. For details, see :doc:`authData <../../server-api/sending-data/authdata>`. |
   +------------------+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

   For example:

   .. code-block:: objective-c
      :caption: Client app

      AlanConfig *config = [[AlanConfig alloc] initWithKey:@"YOUR_KEY_FROM_ALAN_STUDIO_HERE"];


Alan AI button
^^^^^^^^^^^^^^

To add the Alan AI button to your app, use the ``AlanButton`` class. This class provides a view with the AI assistant button and instance methods to communicate with Alan AI Studio.

Сreate a new ``AlanButton`` instance with the config object:

.. code-block:: objective-c
   :caption: Client app

   - (instancetype)initWithConfig:(AlanConfig *)config;

+--------------+--------------+--------------------------------------------------------------------+
| **Name**     | **Type**     | **Description**                                                    |
+==============+==============+====================================================================+
| ``config``   | AlanConfig   | The AlanConfig object for configuration which is described above   |
+--------------+--------------+--------------------------------------------------------------------+

For example:

.. code-block:: objective-c
   :caption: Client app

   @interface ViewController ()
   @property (nonatomic) AlanButton *button;
   @end

   @implementation ViewController
   - (void)viewDidLoad
   {
     [super viewDidLoad];
     AlanConfig *config = [[AlanConfig alloc] initWithKey:@"YOUR_KEY_FROM_ALAN_STUDIO_HERE"];
     self.button = [[AlanButton alloc] initWithConfig:config];
     [self.button setTranslatesAutoresizingMaskIntoConstraints:NO];
     [self.view addSubview:self.button];

     NSLayoutConstraint *right = [NSLayoutConstraint constraintWithItem:self.button attribute:NSLayoutAttributeRight relatedBy:NSLayoutRelationEqual toItem:self.view attribute:NSLayoutAttributeRight multiplier:1 constant:-20.0];
     NSLayoutConstraint *bottom = [NSLayoutConstraint constraintWithItem:self.button attribute:NSLayoutAttributeBottom relatedBy:NSLayoutRelationEqual toItem:self.view attribute:NSLayoutAttributeBottom multiplier:1 constant:-20.0];
     NSLayoutConstraint *width = [NSLayoutConstraint constraintWithItem:self.button attribute:NSLayoutAttributeWidth relatedBy:NSLayoutRelationEqual toItem:nil attribute:NSLayoutAttributeNotAnAttribute multiplier:1 constant:64.0];
     NSLayoutConstraint *height = [NSLayoutConstraint constraintWithItem:self.button attribute:NSLayoutAttributeHeight relatedBy:NSLayoutRelationEqual toItem:nil attribute:NSLayoutAttributeNotAnAttribute multiplier:1 constant:64.0];
     [self.view addConstraints:@[right, bottom, width, height]];
   }
   @end
   
Using client API methods
------------------------

You can use the following :doc:`client API methods <../methods/common-api>` in your app:

-  `setVisualState()`_
-  `callProjectApi()`_
-  `playText()`_
-  `sendText()`_
-  `playCommand()`_
-  `activate()`_
-  `deactivate()`_
-  `isActive()`_
-  `getWakewordEnabled()`_
-  `setWakewordEnabled()`_

setVisualState()
~~~~~~~~~~~~~~~~

Use the ``setVisualState()`` method to inform the AI assistant about the app’s visual context. For details, see :ref:`setVisualState() <setVisualState()>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/visual-state-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/visual-state-swift.rst
   
callProjectApi()
~~~~~~~~~~~~~~~~

Use the ``callProjectApi()`` method to send data from the client app to the dialog script and trigger activities without voice and text commands. For details, see :ref:`callProjectApi() <callProjectApi()>`.

.. code-block:: alan
   :caption: Dialog script

   projectAPI.setClientData = function(p, param, callback) {
     console.log(param);
   };
    
.. tabbed:: Objective-C

   .. include:: ../snippets/project-api-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/project-api-swift.rst
   
playText()
~~~~~~~~~~

Use the ``playText()`` method to play specific text in the client app. For details, see :ref:`playText() <playText()>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/playtext-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/playtext-swift.rst

sendText()
~~~~~~~~~~

Use the ``sendText()`` method to send a text message to Alan AI as the user's input. For details, see :ref:`sendText() <sendText()>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/sendtext-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/sendtext-swift.rst
   
playCommand()
~~~~~~~~~~~~~

Use the ``playCommand()`` method to execute a specific command in the client app. For details, see :ref:`playCommand() <playCommand()>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/playcommand-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/playcommand-swift.rst
   
   
activate()
~~~~~~~~~~

Use the ``activate()`` method to activate the Alan AI button programmatically. For details, see :ref:`activate() <activate()>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/activate-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/activate-swift.rst
   
deactivate()
~~~~~~~~~~~~

Use the ``deactivate()`` method to deactivate the Alan AI button programmatically. For details, see :ref:`deactivate() <deactivate()>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/deactivate-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/deactivate-swift.rst
   
isActive()
~~~~~~~~~~

Use the ``isActive()`` method to check the Alan AI button state: active or not. For details, see :ref:`isActive() <isActive()>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/isactive-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/isactive-swift.rst
   
getWakewordEnabled()
~~~~~~~~~~~~~~~~~~~~

Use the ``getWakewordEnabled()`` method to check the state of the wake word for the Alan AI button. For details, see :ref:`getWakewordEnabled() <getWakewordEnabled()>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/getwakeword-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/getwakeword-swift.rst
   
   
setWakewordEnabled()
~~~~~~~~~~~~~~~~~~~~

Use the ``setWakewordEnabled()`` method to enable or disable the wake word for the Alan AI button. For details, see :ref:`setWakewordEnabled() <setWakewordEnabled()>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/setwakeword-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/setwakeword-swift.rst


Using handlers
--------------

You can use the following :doc:`Alan AI handlers <../methods/handlers>` in your app:

-  `onCommand handler`_
-  `onButtonState handler`_
-  `onEvent handler`_

onCommand handler
~~~~~~~~~~~~~~~~~

Use the ``onCommand`` handler to :ref:`handle commands sent from the dialog script <Sending commands to the app>`. For details, see :doc:`onCommand handler <../methods/command-handler>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/command-handler-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/command-handler-swift.rst

onButtonState handler
~~~~~~~~~~~~~~~~~~~~~

Use the ``onButtonState`` handler to capture and handle the Alan AI button state changes. For details, see :doc:`onButtonState handler <../methods/state-handler>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/state-handler-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/state-handler-swift.rst

onEvent handler
~~~~~~~~~~~~~~~

Use the ``onEvent`` handler to capture and handle events emitted by Alan AI: get user's utterances, assistant responses and so on. For details, see :doc:`onEvent handler <../methods/event-handler>`.

.. tabbed:: Objective-C

   .. include:: ../snippets/event-handler-obj.rst
   
.. tabbed:: Swift

   .. include:: ../snippets/event-handler-swift.rst


What's next?
------------

.. panels::
   :column: col-lg-6 col-md-6 col-sm-6 col-xs-12 p-2

   ---
   :card: border-0 + custom-style-res + git
   
   .. link-button:: https://github.com/alan-ai/alan-sdk-ios/tree/master/examples
      :type: url
      :text: 
      :classes: stretched-link panel
	  
   .. raw:: html
      
	  <p style="font-weight: 600">Example apps</p>
   
   Find and explore examples of AI assistants in Alan AI GitHub.
   
   
   ---
   :card: border-0 + custom-style-res + doc
   
   .. link-button:: ../../tutorials/ios/ios-list
      :type: ref
      :text: 
      :classes: stretched-link panel 
	  
   .. raw:: html
      
	  <p style="font-weight: 600">Tutorials</p>
   
   Learn how to implement common scenarios and workflows for an AI assistant built for an iOS app

.. raw:: html

   <div id="purple-background"></div>
