Testing and debugging
=====================

Testing and debugging are crucial to building a production quality AI assistant. You need to make sure the conversation flow covers all usage scenarios, correct replies are given and the necessary tasks are completed when intents are matched. The Alan AI Platform offers several tools and methods to test and debug your AI assistant:

-  :doc:`Debugging Chat <debugging-chat>`: use the chat to the right of Alan AI Studio to check how separate voice commands or short conversational branches work.
-  :doc:`Tools to simulate in-app behavior <studio-test-tools>`: use these tools to thoroughly test the in-app assistant functionality in Alan AI Studio.
-  :doc:`Test View <test-view>`: switch to the Test View in Alan AI Studio to create test cases covering all required dialog scenarios and run them repeatedly against new versions of dialog scripts.
-  :doc:`Alan AI Studio logs <logs>`: use the logs pane at the bottom of Alan AI Studio to see system messages from the Alan AI Platform along with custom messages written with the ``console.log`` function.
-  :doc:`In-app testing <in-app-testing>`: connect to the AI assistant project from your mobile device to test the assistant functionality in
   the app.
   
   
.. toctree::
   :maxdepth: 1
   :hidden:
   
   Debugging Chat<debugging-chat>
   Tools to simulate in-app behavior<studio-test-tools>
   Test View<test-view>
   Alan AI Studio logs<logs>
   In-app testing<in-app-testing>

.. raw:: html

   <div id="blue-background"></div>
   <div id="wide-content"></div>